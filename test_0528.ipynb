{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4beff4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정의 함수 load\n",
    "from utils.data import *\n",
    "from utils.model import *\n",
    "from utils.metric import *\n",
    "from utils.analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b2570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset List: dt_config/datasets\n",
    "dt_config = dataset_config()\n",
    "datasets= list(dt_config.keys())\n",
    "\n",
    "# print('Dataset List:')\n",
    "# print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce9717b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading region_job dataset from ./dataset/pokec\n",
      "[INFO] 유효하지 않은 user_id로 인해 제거된 edge 수: 0\n",
      "[region_job] sens=0: 43962, sens=1: 23834\n",
      "--------------------------------------------------\n",
      "Loading region_job dataset from ./dataset/pokec\n",
      "[INFO] 유효하지 않은 user_id로 인해 제거된 edge 수: 0\n",
      "[region_job] sens=0: 34308, sens=1: 33488\n",
      "--------------------------------------------------\n",
      "Loading region_job_2 dataset from ./dataset/pokec\n",
      "[INFO] 유효하지 않은 user_id로 인해 제거된 edge 수: 0\n",
      "[region_job_2] sens=0: 47338, sens=1: 19231\n",
      "--------------------------------------------------\n",
      "Loading region_job_2 dataset from ./dataset/pokec\n",
      "[INFO] 유효하지 않은 user_id로 인해 제거된 edge 수: 0\n",
      "[region_job_2] sens=0: 34125, sens=1: 32444\n",
      "--------------------------------------------------\n",
      "Loading nba dataset from ./dataset/NBA\n",
      "[INFO] 유효하지 않은 user_id로 인해 제거된 edge 수: 1641\n",
      "[nba] sens=0: 296, sens=1: 107\n",
      "--------------------------------------------------\n",
      "Loading nba dataset from ./dataset/NBA\n",
      "[INFO] 유효하지 않은 user_id로 인해 제거된 edge 수: 1641\n",
      "[nba] sens=0: 296, sens=1: 107\n",
      "--------------------------------------------------\n",
      "Loading german dataset from ./dataset/NIFTY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\workspace_sy\\DAF-GNN\\utils\\data.py:166: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:620.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[german] sens=0: 310, sens=1: 690\n",
      "--------------------------------------------------\n",
      "Loading german dataset from ./dataset/NIFTY\n",
      "[german] sens=0: 310, sens=1: 690\n",
      "--------------------------------------------------\n",
      "Loading german dataset from ./dataset/NIFTY\n",
      "[german] sens=0: 310, sens=1: 690\n",
      "--------------------------------------------------\n",
      "Loading german dataset from ./dataset/NIFTY\n",
      "[german] sens=0: 310, sens=1: 690\n",
      "--------------------------------------------------\n",
      "Loading german dataset from ./dataset/NIFTY\n",
      "[german] sens=0: 310, sens=1: 690\n",
      "--------------------------------------------------\n",
      "Loading german dataset from ./dataset/NIFTY\n",
      "[german] sens=0: 310, sens=1: 690\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Dataset Load: dt_dict\n",
    "# datasets = [\n",
    "#     'region_job_r', 'region_job_g', 'region_job_2_r', 'region_job_2_g', \n",
    "#     'nba_p', 'nba_m', 'german_g', 'german_f', 'german_s', 'german_t', 'german_h', 'german_e'\n",
    "# ]\n",
    "\n",
    "dt_dict = {}\n",
    "for ds in datasets:\n",
    "    data, df, cfg = load_and_prepare_dataset(dt_config, config_name=ds, seed=1127)\n",
    "    dt_dict[ds] = {\n",
    "        'data': data,\n",
    "        'df': df,\n",
    "        'cfg': cfg\n",
    "    }\n",
    "\n",
    "# Check Dataset: Train/Val/Test 민감속성 비율 동일하게 설정\n",
    "# print_sensitive_attr_distribution(dt_dict['nba_p']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f52805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evluate Dataset: eval_dt_df\n",
    "eval_dt = {}\n",
    "ev_dt_list = ['region_job_r', 'region_job_g', 'region_job_2_r', 'region_job_2_g', 'nba_p', 'german_g']\n",
    "for ds in ev_dt_list:\n",
    "    data = dt_dict[ds]['data']\n",
    "    features = data.x\n",
    "    edge_index = data.edge_index\n",
    "    sens = data.sensitive_attr\n",
    "\n",
    "    eval_dt[ds] = {\n",
    "        \"Homophily Ratio\": homophily_ratio(edge_index, sens),\n",
    "        \"Assortativity Coefficient\": assortativity_coefficient(data),\n",
    "        \"Local Neighborhood Fairness\": local_neighborhood_fairness(edge_index, sens),\n",
    "        \"Degree Balance\": degree_balance(edge_index, sens),\n",
    "        'Structural Bias': structural_bias(features, edge_index, sens)\n",
    "    }\n",
    "\n",
    "eval_dt_df = pd.DataFrame(eval_dt).T\n",
    "print(eval_dt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d27f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Experiments Setting\n",
    "runs=5\n",
    "epochs=500\n",
    "\n",
    "cuda=torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "seed=1127\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# 공통\n",
    "lr=0.001\n",
    "weight_decay=1e-5\n",
    "\n",
    "# model mapping\n",
    "model_map = {\n",
    "    'FnRGNN': lambda data: FnRGNN(nfeat=data.x.size(1), hidden_dim=64, dropout=0.5, lm=3, ld=1, mmd_sample=500, lr=lr, weight_decay=weight_decay),\n",
    "    'FairGNN': lambda data: FairGNN(nfeat=data.x.size(1), hidden_dim=64, model='GCN', dropout=0.5, hidden=128, alpha=4, beta=0.01, lr=lr, weight_decay=weight_decay),\n",
    "    'FMP': lambda data: FMP(data, num_hidden=64, num_layers=5, num_gnn_layer=2, lambda1=3, lambda2=3, dropout=0.5, num_classes=1, L2=True, cached=False),\n",
    "    'GMMD': lambda data: GMMD(in_channels=data.x.size(1), hidden_channels=64),\n",
    "    'EDITS': lambda data: EDITS(nfeat=data.x.size(1), node_num=data.x.size(0), nfeat_out=int(data.x.size(0) / 10), adj_lambda=1e-1, layer_threshold=2, dropout=0.2, lr=lr, weight_decay=weight_decay),\n",
    "    'MLPRegressor': lambda data: MLPRegressor(in_dim=data.x.size(1), hidden_dim=64),\n",
    "    'GCNRegressor': lambda data: GCNRegressor(in_dim=data.x.size(1), hidden_dim=64),\n",
    "    'GATRegressor': lambda data: GATRegressor(in_dim=data.x.size(1), hidden_dim=64, heads=1),\n",
    "    'GraphSAGERegressor': lambda data: GraphSAGERegressor(in_dim=data.x.size(1), hidden_dim=64),\n",
    "    'GINRegressor': lambda data: GINRegressor(in_dim=data.x.size(1), hidden_dim=64),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235c7ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train EDITS dataset from region_job_r\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 17.12 GiB. GPU 0 has a total capacity of 11.99 GiB of which 0 bytes is free. Of the allocated memory 17.60 GiB is allocated by PyTorch, and 145.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m     lr_adj \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.003\u001b[39m\n\u001b[0;32m     90\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 91\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_adj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m md \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGMMD\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     93\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\user\\workspace_sy\\DAF-GNN\\utils\\model.py:670\u001b[0m, in \u001b[0;36mEDITS.optimize\u001b[1;34m(self, adj, features, idx_train, sens, epoch, lr)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 670\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj_renew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    672\u001b[0m predictor_sens, _, X_debiased, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(adj, features)\n\u001b[0;32m    673\u001b[0m pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(predictor_sens[idx_train]\u001b[38;5;241m.\u001b[39msqueeze(), sens[idx_train] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\workspace_sy\\DAF-GNN\\utils\\model.py:571\u001b[0m, in \u001b[0;36mAdj_renew.fit\u001b[1;34m(self, adj, lr)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, adj, lr):\n\u001b[1;32m--> 571\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mEstimateAdj\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator \u001b[38;5;241m=\u001b[39m estimator\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_adj \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(estimator\u001b[38;5;241m.\u001b[39mparameters(), momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, lr\u001b[38;5;241m=\u001b[39mlr)\n",
      "File \u001b[1;32mc:\\Users\\user\\workspace_sy\\DAF-GNN\\utils\\model.py:546\u001b[0m, in \u001b[0;36mEstimateAdj.__init__\u001b[1;34m(self, adj, symmetric, device)\u001b[0m\n\u001b[0;32m    544\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(adj)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimated_adj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mFloatTensor(n, n), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 546\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_estimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymmetric \u001b[38;5;241m=\u001b[39m symmetric\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n",
      "File \u001b[1;32mc:\\Users\\user\\workspace_sy\\DAF-GNN\\utils\\model.py:552\u001b[0m, in \u001b[0;36mEstimateAdj._init_estimation\u001b[1;34m(self, adj)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_init_estimation\u001b[39m(\u001b[38;5;28mself\u001b[39m, adj):\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 552\u001b[0m         adj \u001b[38;5;241m=\u001b[39m \u001b[43madj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimated_adj\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(adj)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 17.12 GiB. GPU 0 has a total capacity of 11.99 GiB of which 0 bytes is free. Of the allocated memory 17.60 GiB is allocated by PyTorch, and 145.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "tr_md_list = ['EDITS', 'FnRGNN', 'FairGNN', 'FMP', 'GMMD', 'MLPRegressor', 'GCNRegressor', 'GATRegressor', 'GraphSAGERegressor', 'GINRegressor']\n",
    "tr_dt_list = ['region_job_r', 'region_job_2_r', 'nba_p', 'nba_m', 'german_g', 'german_f', 'german_s', 'german_t', 'german_h', 'german_e']\n",
    "\n",
    "for ds in tr_dt_list:\n",
    "    data = dt_dict[ds]['data']\n",
    "    data = data.to(device)\n",
    "\n",
    "    cfg = dt_dict[ds]['cfg']\n",
    "    dn = cfg['dn']\n",
    "\n",
    "    for md in tr_md_list:\n",
    "        print(f'Train {md} dataset from {ds}')\n",
    "        os.makedirs(f'./model/{md}', exist_ok=True) \n",
    "        model_path = f'./model/{md}/{dn}_md.pth'\n",
    "\n",
    "        if md == 'FairGNN':\n",
    "            print(f'Train FairGNN Sensitive Model dataset from {ds}')\n",
    "            \n",
    "            fair_sen_model = GCN(nfeat=data.x.shape[1], nhid=128, nclass=1, dropout=0.5).to(device)\n",
    "            fair_optimizer = optim.Adam(fair_sen_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "            criterion = torch.nn.MSELoss()\n",
    "            best_mse = float('inf')\n",
    "            best_result = {}\n",
    "\n",
    "            for epoch in range(epochs + 1):    \n",
    "                fair_sen_model.train()\n",
    "                fair_optimizer.zero_grad()\n",
    "                output = fair_sen_model(data.x, data.edge_index)\n",
    "                loss = criterion(output[data.idx_train], data.y[data.idx_train].unsqueeze(1))\n",
    "                loss.backward()\n",
    "                fair_optimizer.step()\n",
    "\n",
    "                fair_fastmode=False\n",
    "                if not fair_fastmode:\n",
    "                    fair_sen_model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        output = fair_sen_model(data.x, data.edge_index)\n",
    "                        mse_val = mean_squared_error(data.sensitive_attr[data.idx_val].cpu().numpy(), output[data.idx_val].cpu().numpy())\n",
    "                        mse_test = mean_squared_error(data.sensitive_attr[data.idx_test].cpu().numpy(), output[data.idx_test].cpu().numpy())\n",
    "\n",
    "                if epoch % 50 == 0:\n",
    "                    print(f\"Epoch [{epoch}] Test set results:\",\n",
    "                        f\"mse_val={mse_val:.4f}, mse_test={mse_test:.4f}\")\n",
    "\n",
    "                    if mse_val < best_mse:\n",
    "                        best_mse = mse_val\n",
    "                        best_result = {'mse': mse_test}\n",
    "                        torch.save(fair_sen_model.state_dict(), f\"./checkpoint/GCN_sens_{ds}_ns_{cfg['sens_number']}\")\n",
    "\n",
    "            print(f\"The best MSE of estimator: {best_result['mse']:.4f}\")\n",
    "            print(\"Optimization Finished!\")\n",
    "        \n",
    "        for run in range(runs + 1):\n",
    "            model = model_map[md](data).to(device)\n",
    "\n",
    "            if md not in ['FnRGNN', 'FairGNN', 'EDITS']:\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "                criterion = torch.nn.MSELoss()\n",
    "            elif md == 'FairGNN':\n",
    "                try:\n",
    "                    model.estimator.load_state_dict(torch.load( f\"./checkpoint/GCN_sens_{ds}_ns_{cfg['sens_number']}\", map_location=torch.device(device) ))\n",
    "                except Exception as e:\n",
    "                    print(f\"Checkpoint load failed: {e}\")\n",
    "            elif md == 'EDITS':\n",
    "                features = data.x.to(device).to(torch.float32)\n",
    "                labels = data.y.to(device).to(torch.float32)\n",
    "                sens = data.sensitive_attr.to(device).to(torch.float32)\n",
    "\n",
    "                adj = data.adj\n",
    "                if isinstance(adj, torch.Tensor):\n",
    "                    adj = adj.to(device).to(torch.float32)\n",
    "                else:\n",
    "                    adj = torch.FloatTensor(adj.toarray()).to(device).to(torch.float32)\n",
    "\n",
    "                idx_train = data.idx_train\n",
    "                idx_val = data.idx_val\n",
    "                idx_test = data.idx_test\n",
    "            \n",
    "            best_score = float('inf')\n",
    "            best_model_state = None\n",
    "\n",
    "            for epoch in range(epochs + 1):\n",
    "                if md == 'FnRGNN':\n",
    "                    loss = model.optimize(data)\n",
    "                elif md == 'FairGNN':\n",
    "                    model.optimize(data)\n",
    "                elif md == 'EDITS':\n",
    "                    lr_adj = 0.001 if epoch > 400 else 0.003\n",
    "                    model.train()\n",
    "                    model.optimize(adj, features, idx_train, sens, epoch, lr_adj)\n",
    "                elif md == 'GMMD':\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    pred, mmd_loss = model(data)\n",
    "                    pred = pred.squeeze()\n",
    "                    loss = mmd_loss + criterion(pred[data.idx_train], data.y[data.idx_train].squeeze())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output[data.idx_train], data.y[data.idx_train].unsqueeze(1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # validation\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    if md == 'EDITS':\n",
    "                        adj_sparse = to_scipy_sparse_matrix(data.edge_index).tocoo()\n",
    "                        adj = sparse_mx_to_torch_sparse_tensor(adj_sparse).to(device)\n",
    "                        features = data.x\n",
    "                        if not hasattr(model.adj_renew, \"estimator\"):\n",
    "                            model.adj_renew.fit(adj, lr=0.003)\n",
    "                        output = model(adj, features)[2]\n",
    "                    elif md in ['FnRGNN', 'FairGNN', 'GMMD']:\n",
    "                        output, _ = model(data)\n",
    "                    else:\n",
    "                        output = model(data)\n",
    "\n",
    "                    y_true, idx_val, sensitive_attr = data.y, data.idx_val, data.sensitive_attr\n",
    "                    mse_val = mean_squared_error(y_true[idx_val].cpu(), output[idx_val].cpu())\n",
    "                    mae_val = mean_absolute_error(y_true[idx_val].cpu(), output[idx_val].cpu())\n",
    "                    mse_diff, mae_diff, mean_diff = fair_metric_regression(output[idx_val].cpu(), y_true[idx_val].cpu(), sensitive_attr[idx_val].cpu())\n",
    "                    dist_val = group_distribution_metrics(y_true[idx_val].cpu().numpy().squeeze(), output[idx_val].cpu().numpy().squeeze(), sensitive_attr[idx_val].cpu().numpy())\n",
    "                    \n",
    "                    if md == 'FnRGNN':\n",
    "                        val_score = mse_val + 0.5 * mean_diff\n",
    "                    else:\n",
    "                        val_score = mse_val\n",
    "\n",
    "                    if val_score < best_score:\n",
    "                        best_mse = val_score\n",
    "                        best_model_state = copy.deepcopy(model.state_dict())\n",
    "                        torch.save(best_model_state, model_path)\n",
    "                    \n",
    "                    if epoch % 50 == 0:\n",
    "                        print(f\"[{md}] Run {run}, Epoch {epoch} | \"\n",
    "                            f\"Val MSE: {mse_val:.2f}, MAE: {mae_val:.2f}, \\n\"\n",
    "                            f\"MSE Diff: {mse_diff:.2f}, MAE Diff: {mae_diff:.2f}, MEAN Diff: {mean_diff:.2f}, \"\n",
    "                            f\"Wasserstein Diff: {dist_val['wasserstein_diff']:.2f}, JS Diff: {dist_val['js_diff']:.2f}\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32859e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "ts_md_list = ['FnRGNN', 'FairGNN', 'FMP', 'GMMD', 'EDITS', 'MLPRegressor', 'GCNRegressor', 'GATRegressor', 'GraphSAGERegressor', 'GINRegressor']\n",
    "ts_dt_list = ['region_job_r', 'region_job_2_r', 'nba_p', 'nba_m', 'german_g', 'german_f', 'german_s', 'german_t', 'german_h', 'german_e']\n",
    "\n",
    "ts_results = {}\n",
    "for ds in ts_dt_list:\n",
    "    data = dt_dict[ds]['data']\n",
    "    data = data.to(device)\n",
    "\n",
    "    cfg = dt_dict[ds]['cfg']\n",
    "    dn = cfg['dn']\n",
    "\n",
    "    md_results = {}\n",
    "    for md in ts_md_list:\n",
    "        print(f'Test {md} dataset from {ds}')\n",
    "\n",
    "        result = []\n",
    "        for run in range(runs + 1):\n",
    "            model = model_map[md](data).to(device)\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                if md == 'EDITS':\n",
    "                    adj_sparse = to_scipy_sparse_matrix(data.edge_index).tocoo()\n",
    "                    adj = sparse_mx_to_torch_sparse_tensor(adj_sparse).to(device)\n",
    "                    features = data.x\n",
    "                    if not hasattr(model.adj_renew, \"estimator\"):\n",
    "                        model.adj_renew.fit(adj, lr=0.003)\n",
    "                    output = model(adj, features)[2]\n",
    "                elif md in ['FnRGNN', 'FairGNN', 'GMMD']:\n",
    "                    output, _ = model(data)\n",
    "                else:\n",
    "                    output = model(data)\n",
    "\n",
    "                y_true, idx_test, sensitive_attr = data.y, data.idx_test, data.sensitive_attr\n",
    "                mse_test = mean_squared_error(y_true[idx_test].cpu(), output[idx_test].cpu())\n",
    "                mae_test = mean_absolute_error(y_true[idx_test].cpu(), output[idx_test].cpu())\n",
    "                mse_diff, mae_diff, mean_diff = fair_metric_regression(output[idx_test].cpu(), y_true[idx_test].cpu(), sensitive_attr[idx_test].cpu())\n",
    "                dist_test = group_distribution_metrics(y_true[idx_test].cpu().numpy().squeeze(), output[idx_test].cpu().numpy().squeeze(), sensitive_attr[idx_test].cpu().numpy())\n",
    "                \n",
    "            result.append([mse_test, mae_test, mse_diff, mae_diff, mean_diff, dist_test])\n",
    "                \n",
    "        md_results[ds] = result\n",
    "\n",
    "    ts_results[md] = md_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
